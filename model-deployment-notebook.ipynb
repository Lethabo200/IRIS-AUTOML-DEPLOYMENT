{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment for Iris Classification\n",
    "\n",
    "In this notebook, we'll deploy the best model we trained using Azure AutoML as a web service. We'll perform the following steps:\n",
    "1. Connect to the Azure ML workspace\n",
    "2. Load the trained model and necessary files\n",
    "3. Define inference configuration\n",
    "4. Define deployment configuration\n",
    "5. Deploy the model\n",
    "6. Test the deployed service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to the Azure ML workspace and load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Model, Run\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.automl.core.shared import constants\n",
    "\n",
    "# Connect to your workspace\n",
    "ws = Workspace.from_config()\n",
    "print(f\"Connected to workspace: {ws.name}\")\n",
    "\n",
    "# Get the latest run\n",
    "experiment = Run.get_context().experiment\n",
    "latest_run = list(experiment.get_runs())[0]\n",
    "best_run = latest_run.get_best_child()\n",
    "print(f\"Best run ID: {best_run.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the trained model and necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the scoring file for the best model from the Azure ML run's output and save it locally\n",
    "best_run.download_file('outputs/scoring_file_v_1_0_0.py', 'inference/score.py')\n",
    "\n",
    "# Download the Conda environment file used by the best model and save it locally\n",
    "best_run.download_file(constants.CONDA_ENV_FILE_PATH, 'myenv.yml')\n",
    "\n",
    "# Create an Azure ML environment using the downloaded Conda specification\n",
    "env = Environment.from_conda_specification(name='myenv', file_path='myenv.yml')\n",
    "\n",
    "# Load the model\n",
    "model = best_run.register_model(model_name=\"iris_classification_model\", model_path='outputs/model.pkl')\n",
    "print(f\"Model registered: {model.name}, version: {model.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define inference configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the inference configuration using the scoring script and the environment\n",
    "inference_config = InferenceConfig(entry_script='inference/score.py', environment=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define deployment configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the deployment configuration for an ACI web service with 1.5 CPU cores, 1 GB of memory, and a description\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1.5, memory_gb=1, description='Iris')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_name = 'iris-classification-service'\n",
    "\n",
    "service = Model.deploy(ws,\n",
    "                       service_name,\n",
    "                       [model],\n",
    "                       inference_config,\n",
    "                       aciconfig)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(f\"Service state: {service.state}\")\n",
    "print(f\"Service URL: {service.scoring_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test the deployed service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Test data\n",
    "test_data = json.dumps({'data': [[5.1, 3.5, 1.4, 0.2]]})\n",
    "\n",
    "# Set the content type\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "# Send the request\n",
    "response = requests.post(service.scoring_uri, test_data, headers=headers)\n",
    "\n",
    "print(f\"Prediction: {response.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We've successfully deployed our Iris classification model as a web service using Azure Container Instances. The service is now ready to accept HTTP requests and return predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
